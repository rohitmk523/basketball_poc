{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Basketball Video Analysis POC\n",
    "## Automated Event Detection and Processing Pipeline\n",
    "\n",
    "This notebook implements a comprehensive basketball video analysis system that:\n",
    "- Processes 15-minute basketball video clips\n",
    "- Detects key events: 2pt/3pt shots, assists, steals, blocks\n",
    "- Generates structured JSON outputs and annotated videos\n",
    "- Uses Gemini Pro 2.5 for video understanding and event extraction\n",
    "\n",
    "### Architecture Overview\n",
    "1. **Video Segmentation**: Split videos into 30-second processable chunks\n",
    "2. **VLM Analysis**: Gemini Pro 2.5 generates dense captions for each chunk\n",
    "3. **Event Synthesis**: LLM cleans and structures events into final logs\n",
    "4. **Output Generation**: Creates JSON reports and timeline video overlays\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 1. Setup and Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (0.8.5)\n",
      "Requirement already satisfied: opencv-python in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (4.12.0.88)\n",
      "Requirement already satisfied: moviepy in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (2.2.1)\n",
      "Requirement already satisfied: youtube-dl in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (2021.12.17)\n",
      "Requirement already satisfied: yt-dlp in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (2025.7.21)\n",
      "Requirement already satisfied: ffmpeg-python in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (0.2.0)\n",
      "Requirement already satisfied: pillow in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (11.3.0)\n",
      "Requirement already satisfied: numpy in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (2.2.6)\n",
      "Requirement already satisfied: pandas in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (2.3.1)\n",
      "Requirement already satisfied: matplotlib in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (3.10.3)\n",
      "Requirement already satisfied: seaborn in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (0.13.2)\n",
      "Requirement already satisfied: tqdm in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (4.67.1)\n",
      "Requirement already satisfied: python-dotenv in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (1.1.1)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (from google-generativeai) (2.25.1)\n",
      "Requirement already satisfied: google-api-python-client in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (from google-generativeai) (2.177.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (from google-generativeai) (2.40.3)\n",
      "Requirement already satisfied: protobuf in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (from google-generativeai) (5.29.5)\n",
      "Requirement already satisfied: pydantic in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (from google-generativeai) (2.11.7)\n",
      "Requirement already satisfied: typing-extensions in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (from google-generativeai) (4.14.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (from google-api-core->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (from google-api-core->google-generativeai) (2.32.4)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.74.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.7.14)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: decorator<6.0,>=4.0.2 in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (from moviepy) (5.2.1)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (from moviepy) (2.37.0)\n",
      "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (from moviepy) (0.6.0)\n",
      "Requirement already satisfied: proglog<=1.0.0 in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (from moviepy) (0.1.12)\n",
      "Requirement already satisfied: future in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (from ffmpeg-python) (1.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (from matplotlib) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (from pydantic->google-generativeai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/rohitkale/miniconda3/envs/basketball/lib/python3.11/site-packages (from pydantic->google-generativeai) (0.4.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "%pip install google-generativeai opencv-python moviepy youtube-dl yt-dlp ffmpeg-python pillow numpy pandas matplotlib seaborn tqdm python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All dependencies imported successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple, Optional, Union\n",
    "from dataclasses import dataclass, asdict\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Video processing\n",
    "from moviepy import VideoFileClip, TextClip, CompositeVideoClip, ColorClip\n",
    "import ffmpeg\n",
    "\n",
    "# Google Gemini API\n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"âœ… All dependencies imported successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 2. Configuration and Data Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸  GEMINI_API_KEY not found in environment variables\n",
      "Please set your Gemini API key:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your Gemini API key:  AIzaSyBAsS7OV2daJAhf0YxcBtZBwGGPpid_iuc\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "class Config:\n",
    "    # API Configuration\n",
    "    GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n",
    "    GEMINI_MODEL = 'gemini-2.5-pro'  # Using latest thinking model\n",
    "    \n",
    "    # Video Processing\n",
    "    SEGMENT_DURATION = 30  # seconds\n",
    "    MAX_VIDEO_DURATION = 15 * 60  # 15 minutes\n",
    "    OUTPUT_FPS = 30\n",
    "    \n",
    "    # Directories\n",
    "    DATA_DIR = Path('data')\n",
    "    OUTPUT_DIR = Path('output')\n",
    "    TEMP_DIR = Path('temp')\n",
    "    \n",
    "    # Event Detection\n",
    "    TARGET_EVENTS = ['2pt_shot', '3pt_shot', 'assist', 'steal', 'block']\n",
    "    ASSIST_TIME_WINDOW = 2  # seconds\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        # Create directories\n",
    "        for dir_path in [self.DATA_DIR, self.OUTPUT_DIR, self.TEMP_DIR]:\n",
    "            dir_path.mkdir(exist_ok=True)\n",
    "\n",
    "config = Config()\n",
    "config.__post_init__()\n",
    "\n",
    "# Verify API key\n",
    "if not config.GEMINI_API_KEY:\n",
    "    print(\"âš ï¸  GEMINI_API_KEY not found in environment variables\")\n",
    "    print(\"Please set your Gemini API key:\")\n",
    "    config.GEMINI_API_KEY = input(\"Enter your Gemini API key: \")\n",
    "else:\n",
    "    print(\"âœ… Gemini API key loaded from environment\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data models defined\n"
     ]
    }
   ],
   "source": [
    "# Data Models\n",
    "@dataclass\n",
    "class BasketballEvent:\n",
    "    \"\"\"Represents a detected basketball event\"\"\"\n",
    "    event_type: str  # '2pt_shot', '3pt_shot', 'assist', 'steal', 'block'\n",
    "    timestamp: float  # seconds from video start\n",
    "    duration: float  # event duration in seconds\n",
    "    description: str  # natural language description\n",
    "    confidence: float  # confidence score 0-1\n",
    "    outcome: Optional[str] = None  # 'made', 'missed' for shots\n",
    "    location: Optional[str] = None  # court location description\n",
    "    segment_id: Optional[int] = None  # which 30s segment this came from\n",
    "    \n",
    "@dataclass\n",
    "class VideoSegment:\n",
    "    \"\"\"Represents a 30-second video segment\"\"\"\n",
    "    segment_id: int\n",
    "    start_time: float\n",
    "    end_time: float\n",
    "    file_path: str\n",
    "    processed: bool = False\n",
    "    events: List[BasketballEvent] = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.events is None:\n",
    "            self.events = []\n",
    "\n",
    "@dataclass\n",
    "class GameStatistics:\n",
    "    \"\"\"Aggregated game statistics\"\"\"\n",
    "    total_2pt_attempts: int = 0\n",
    "    total_2pt_made: int = 0\n",
    "    total_3pt_attempts: int = 0\n",
    "    total_3pt_made: int = 0\n",
    "    total_assists: int = 0\n",
    "    total_steals: int = 0\n",
    "    total_blocks: int = 0\n",
    "    \n",
    "    @property\n",
    "    def fg_percentage_2pt(self) -> float:\n",
    "        return (self.total_2pt_made / self.total_2pt_attempts * 100) if self.total_2pt_attempts > 0 else 0.0\n",
    "    \n",
    "    @property\n",
    "    def fg_percentage_3pt(self) -> float:\n",
    "        return (self.total_3pt_made / self.total_3pt_attempts * 100) if self.total_3pt_attempts > 0 else 0.0\n",
    "\n",
    "@dataclass\n",
    "class ProcessingResult:\n",
    "    \"\"\"Complete processing result for a video\"\"\"\n",
    "    video_path: str\n",
    "    processing_time: float\n",
    "    total_segments: int\n",
    "    events: List[BasketballEvent]\n",
    "    statistics: GameStatistics\n",
    "    output_files: Dict[str, str]  # type -> file_path\n",
    "    \n",
    "print(\"âœ… Data models defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 3. Gemini API Integration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-01 18:17:27,673 - INFO - Initialized Gemini model: gemini-2.5-pro\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Gemini Video Analyzer initialized\n"
     ]
    }
   ],
   "source": [
    "class GeminiVideoAnalyzer:\n",
    "    \"\"\"Handles video analysis using Gemini Pro 2.5 Thinking\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: str, model_name: str = 'gemini-2.0-flash-thinking-exp'):\n",
    "        genai.configure(api_key=api_key)\n",
    "        self.model = genai.GenerativeModel(\n",
    "            model_name=model_name,\n",
    "            generation_config=genai.types.GenerationConfig(\n",
    "                temperature=0.1,  # Low temperature for consistent analysis\n",
    "                top_p=0.8,\n",
    "                top_k=40,\n",
    "                max_output_tokens=2048,\n",
    "            ),\n",
    "            safety_settings={\n",
    "                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "            }\n",
    "        )\n",
    "        logger.info(f\"Initialized Gemini model: {model_name}\")\n",
    "    \n",
    "    def analyze_video_segment(self, video_path: str, segment_start: float, segment_end: float) -> str:\n",
    "        \"\"\"Analyze a video segment and return dense captions\"\"\"\n",
    "        try:\n",
    "            # Upload video file\n",
    "            video_file = genai.upload_file(video_path)\n",
    "            \n",
    "            # Wait for processing\n",
    "            while video_file.state.name == \"PROCESSING\":\n",
    "                time.sleep(2)\n",
    "                video_file = genai.get_file(video_file.name)\n",
    "            \n",
    "            if video_file.state.name == \"FAILED\":\n",
    "                raise ValueError(f\"Video processing failed: {video_file.state}\")\n",
    "            \n",
    "            # Create basketball-optimized prompt\n",
    "            prompt = self._create_analysis_prompt(segment_start, segment_end)\n",
    "            \n",
    "            # Generate response\n",
    "            response = self.model.generate_content([video_file, prompt])\n",
    "            \n",
    "            # Clean up uploaded file\n",
    "            genai.delete_file(video_file.name)\n",
    "            \n",
    "            return response.text\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error analyzing video segment: {e}\")\n",
    "            return f\"Error: {str(e)}\"\n",
    "    \n",
    "    def _create_analysis_prompt(self, start_time: float, end_time: float) -> str:\n",
    "        \"\"\"Create optimized prompt for basketball event detection\"\"\"\n",
    "        return f\"\"\"\n",
    "Analyze this basketball video segment (from {start_time:.1f}s to {end_time:.1f}s) and detect the following events with precise timing:\n",
    "\n",
    "TARGET EVENTS:\n",
    "1. **Shot Attempts**: \n",
    "   - 2-point shots (inside the arc) - specify if made/missed\n",
    "   - 3-point shots (beyond the arc) - specify if made/missed\n",
    "   - Provide exact timestamp and shooting location\n",
    "\n",
    "2. **Assists**: \n",
    "   - Passes that directly lead to made baskets within 2 seconds\n",
    "   - Include the pass timestamp and the subsequent score\n",
    "\n",
    "3. **Defensive Actions**:\n",
    "   - Steals: When a player takes possession from opponent\n",
    "   - Blocks: When a shot is deflected/blocked\n",
    "   - Include precise timing and description\n",
    "\n",
    "ANALYSIS REQUIREMENTS:\n",
    "- Provide exact timestamps (relative to segment start)\n",
    "- Classify each event with confidence level (1-10)\n",
    "- Give clear descriptions of what happened\n",
    "- Focus only on clear, unambiguous events\n",
    "- If no events occur, explicitly state \"No basketball events detected\"\n",
    "\n",
    "FORMAT YOUR RESPONSE AS:\n",
    "```\n",
    "TIMESTAMP: [seconds]s\n",
    "EVENT: [event_type]\n",
    "OUTCOME: [made/missed for shots, N/A for others]\n",
    "DESCRIPTION: [detailed description]\n",
    "CONFIDENCE: [1-10]\n",
    "LOCATION: [court area]\n",
    "---\n",
    "```\n",
    "\n",
    "Analyze the video carefully and report all detected basketball events.\"\"\"\n",
    "\n",
    "# Initialize analyzer\n",
    "if config.GEMINI_API_KEY:\n",
    "    gemini_analyzer = GeminiVideoAnalyzer(config.GEMINI_API_KEY, config.GEMINI_MODEL)\n",
    "    print(\"âœ… Gemini Video Analyzer initialized\")\n",
    "else:\n",
    "    print(\"âš ï¸  Gemini API key required to initialize analyzer\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 4. Video Processing Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Video Processor initialized\n"
     ]
    }
   ],
   "source": [
    "class VideoProcessor:\n",
    "    \"\"\"Handles video segmentation and processing\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "    \n",
    "    def segment_video(self, video_path: str) -> List[VideoSegment]:\n",
    "        \"\"\"Split video into 30-second segments\"\"\"\n",
    "        try:\n",
    "            # Get video info\n",
    "            clip = VideoFileClip(video_path)\n",
    "            duration = clip.duration\n",
    "            clip.close()\n",
    "            \n",
    "            logger.info(f\"Video duration: {duration:.2f} seconds\")\n",
    "            \n",
    "            # Limit to max duration\n",
    "            if duration > self.config.MAX_VIDEO_DURATION:\n",
    "                duration = self.config.MAX_VIDEO_DURATION\n",
    "                logger.warning(f\"Video truncated to {self.config.MAX_VIDEO_DURATION} seconds\")\n",
    "            \n",
    "            # Create segments\n",
    "            segments = []\n",
    "            segment_id = 0\n",
    "            \n",
    "            for start_time in range(0, int(duration), self.config.SEGMENT_DURATION):\n",
    "                end_time = min(start_time + self.config.SEGMENT_DURATION, duration)\n",
    "                \n",
    "                # Create segment file path\n",
    "                segment_filename = f\"segment_{segment_id:03d}_{start_time}_{int(end_time)}.mp4\"\n",
    "                segment_path = self.config.TEMP_DIR / segment_filename\n",
    "                \n",
    "                segments.append(VideoSegment(\n",
    "                    segment_id=segment_id,\n",
    "                    start_time=start_time,\n",
    "                    end_time=end_time,\n",
    "                    file_path=str(segment_path)\n",
    "                ))\n",
    "                \n",
    "                segment_id += 1\n",
    "            \n",
    "            logger.info(f\"Created {len(segments)} segments\")\n",
    "            return segments\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error segmenting video: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def extract_segment(self, video_path: str, segment: VideoSegment) -> bool:\n",
    "        \"\"\"Extract a specific segment from the video\"\"\"\n",
    "        try:\n",
    "            # Extract using moviepy\n",
    "            clip = VideoFileClip(video_path)\n",
    "            segment_clip = clip[segment.start_time:segment.end_time]\n",
    "            segment_clip.write_videofile(\n",
    "                segment.file_path,\n",
    "                fps=self.config.OUTPUT_FPS,\n",
    "                logger=None\n",
    "            )\n",
    "            \n",
    "            segment_clip.close()\n",
    "            clip.close()\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error extracting segment {segment.segment_id}: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def get_video_info(self, video_path: str) -> Dict:\n",
    "        \"\"\"Get basic video information\"\"\"\n",
    "        try:\n",
    "            clip = VideoFileClip(video_path)\n",
    "            info = {\n",
    "                'duration': clip.duration,\n",
    "                'fps': clip.fps,\n",
    "                'size': clip.size,\n",
    "                'filename': Path(video_path).name\n",
    "            }\n",
    "            clip.close()\n",
    "            return info\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error getting video info: {e}\")\n",
    "            return {}\n",
    "\n",
    "# Initialize processor\n",
    "video_processor = VideoProcessor(config)\n",
    "print(\"âœ… Video Processor initialized\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 5. Event Synthesis and Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Event Synthesizer initialized\n"
     ]
    }
   ],
   "source": [
    "class EventSynthesizer:\n",
    "    \"\"\"Processes raw captions and extracts structured events\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "    \n",
    "    def parse_gemini_output(self, raw_output: str, segment: VideoSegment) -> List[BasketballEvent]:\n",
    "        \"\"\"Parse Gemini output into structured events\"\"\"\n",
    "        events = []\n",
    "        \n",
    "        try:\n",
    "            # Split by event separators\n",
    "            event_blocks = raw_output.split('---')\n",
    "            \n",
    "            for block in event_blocks:\n",
    "                block = block.strip()\n",
    "                if not block or 'No basketball events detected' in block:\n",
    "                    continue\n",
    "                \n",
    "                event = self._parse_event_block(block, segment)\n",
    "                if event:\n",
    "                    events.append(event)\n",
    "            \n",
    "            logger.info(f\"Parsed {len(events)} events from segment {segment.segment_id}\")\n",
    "            return events\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error parsing events: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def _parse_event_block(self, block: str, segment: VideoSegment) -> Optional[BasketballEvent]:\n",
    "        \"\"\"Parse individual event block\"\"\"\n",
    "        try:\n",
    "            lines = [line.strip() for line in block.split('\\n') if line.strip()]\n",
    "            \n",
    "            # Extract fields\n",
    "            timestamp = None\n",
    "            event_type = None\n",
    "            outcome = None\n",
    "            description = \"\"\n",
    "            confidence = 0.5\n",
    "            location = \"\"\n",
    "            \n",
    "            for line in lines:\n",
    "                if line.startswith('TIMESTAMP:'):\n",
    "                    timestamp_str = line.replace('TIMESTAMP:', '').strip().replace('s', '')\n",
    "                    timestamp = float(timestamp_str) + segment.start_time  # Adjust to video time\n",
    "                elif line.startswith('EVENT:'):\n",
    "                    event_type = self._normalize_event_type(line.replace('EVENT:', '').strip())\n",
    "                elif line.startswith('OUTCOME:'):\n",
    "                    outcome = line.replace('OUTCOME:', '').strip().lower()\n",
    "                    if outcome == 'n/a':\n",
    "                        outcome = None\n",
    "                elif line.startswith('DESCRIPTION:'):\n",
    "                    description = line.replace('DESCRIPTION:', '').strip()\n",
    "                elif line.startswith('CONFIDENCE:'):\n",
    "                    conf_str = line.replace('CONFIDENCE:', '').strip()\n",
    "                    confidence = float(conf_str) / 10.0  # Convert 1-10 to 0-1\n",
    "                elif line.startswith('LOCATION:'):\n",
    "                    location = line.replace('LOCATION:', '').strip()\n",
    "            \n",
    "            # Validate required fields\n",
    "            if timestamp is None or event_type is None:\n",
    "                return None\n",
    "            \n",
    "            return BasketballEvent(\n",
    "                event_type=event_type,\n",
    "                timestamp=timestamp,\n",
    "                duration=1.0,  # Default duration\n",
    "                description=description,\n",
    "                confidence=confidence,\n",
    "                outcome=outcome,\n",
    "                location=location,\n",
    "                segment_id=segment.segment_id\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error parsing event block: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _normalize_event_type(self, event_type: str) -> str:\n",
    "        \"\"\"Normalize event type to standard format\"\"\"\n",
    "        event_type = event_type.lower().strip()\n",
    "        \n",
    "        # Mapping variations to standard types\n",
    "        mappings = {\n",
    "            '2-point shot': '2pt_shot',\n",
    "            '2pt shot': '2pt_shot',\n",
    "            '2 point shot': '2pt_shot',\n",
    "            'two point shot': '2pt_shot',\n",
    "            '3-point shot': '3pt_shot',\n",
    "            '3pt shot': '3pt_shot',\n",
    "            '3 point shot': '3pt_shot',\n",
    "            'three point shot': '3pt_shot',\n",
    "            'assist': 'assist',\n",
    "            'steal': 'steal',\n",
    "            'block': 'block',\n",
    "            'shot block': 'block'\n",
    "        }\n",
    "        \n",
    "        for key, value in mappings.items():\n",
    "            if key in event_type:\n",
    "                return value\n",
    "        \n",
    "        return event_type\n",
    "    \n",
    "    def deduplicate_events(self, events: List[BasketballEvent]) -> List[BasketballEvent]:\n",
    "        \"\"\"Remove duplicate events across segment boundaries\"\"\"\n",
    "        if not events:\n",
    "            return events\n",
    "        \n",
    "        # Sort by timestamp\n",
    "        events.sort(key=lambda x: x.timestamp)\n",
    "        \n",
    "        deduplicated = [events[0]]\n",
    "        \n",
    "        for event in events[1:]:\n",
    "            # Check if this event is too close to the last one\n",
    "            last_event = deduplicated[-1]\n",
    "            time_diff = abs(event.timestamp - last_event.timestamp)\n",
    "            \n",
    "            # If events are within 3 seconds and same type, consider duplicate\n",
    "            if time_diff < 3.0 and event.event_type == last_event.event_type:\n",
    "                # Keep the one with higher confidence\n",
    "                if event.confidence > last_event.confidence:\n",
    "                    deduplicated[-1] = event\n",
    "            else:\n",
    "                deduplicated.append(event)\n",
    "        \n",
    "        logger.info(f\"Deduplicated {len(events)} -> {len(deduplicated)} events\")\n",
    "        return deduplicated\n",
    "\n",
    "# Initialize synthesizer\n",
    "event_synthesizer = EventSynthesizer(config)\n",
    "print(\"âœ… Event Synthesizer initialized\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 6. Statistics Calculator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Statistics Calculator defined\n"
     ]
    }
   ],
   "source": [
    "class StatisticsCalculator:\n",
    "    \"\"\"Calculate game statistics from detected events\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_statistics(events: List[BasketballEvent]) -> GameStatistics:\n",
    "        \"\"\"Calculate comprehensive game statistics\"\"\"\n",
    "        stats = GameStatistics()\n",
    "        \n",
    "        for event in events:\n",
    "            if event.event_type == '2pt_shot':\n",
    "                stats.total_2pt_attempts += 1\n",
    "                if event.outcome == 'made':\n",
    "                    stats.total_2pt_made += 1\n",
    "            \n",
    "            elif event.event_type == '3pt_shot':\n",
    "                stats.total_3pt_attempts += 1\n",
    "                if event.outcome == 'made':\n",
    "                    stats.total_3pt_made += 1\n",
    "            \n",
    "            elif event.event_type == 'assist':\n",
    "                stats.total_assists += 1\n",
    "            \n",
    "            elif event.event_type == 'steal':\n",
    "                stats.total_steals += 1\n",
    "            \n",
    "            elif event.event_type == 'block':\n",
    "                stats.total_blocks += 1\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_timeline_data(events: List[BasketballEvent]) -> pd.DataFrame:\n",
    "        \"\"\"Create timeline data for visualization\"\"\"\n",
    "        if not events:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        timeline_data = []\n",
    "        for event in events:\n",
    "            timeline_data.append({\n",
    "                'timestamp': event.timestamp,\n",
    "                'event_type': event.event_type,\n",
    "                'outcome': event.outcome,\n",
    "                'description': event.description,\n",
    "                'confidence': event.confidence,\n",
    "                'location': event.location\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(timeline_data)\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_summary_report(stats: GameStatistics, events: List[BasketballEvent], \n",
    "                               video_info: Dict) -> Dict:\n",
    "        \"\"\"Generate comprehensive summary report\"\"\"\n",
    "        return {\n",
    "            'video_info': video_info,\n",
    "            'processing_summary': {\n",
    "                'total_events_detected': len(events),\n",
    "                'processing_timestamp': datetime.now().isoformat(),\n",
    "                'event_types_found': list(set(event.event_type for event in events))\n",
    "            },\n",
    "            'game_statistics': asdict(stats),\n",
    "            'shooting_analysis': {\n",
    "                '2pt_shooting': {\n",
    "                    'percentage': stats.fg_percentage_2pt,\n",
    "                    'made': stats.total_2pt_made,\n",
    "                    'attempts': stats.total_2pt_attempts\n",
    "                },\n",
    "                '3pt_shooting': {\n",
    "                    'percentage': stats.fg_percentage_3pt,\n",
    "                    'made': stats.total_3pt_made,\n",
    "                    'attempts': stats.total_3pt_attempts\n",
    "                },\n",
    "                'overall_fg_percentage': (\n",
    "                    (stats.total_2pt_made + stats.total_3pt_made) / \n",
    "                    (stats.total_2pt_attempts + stats.total_3pt_attempts) * 100\n",
    "                ) if (stats.total_2pt_attempts + stats.total_3pt_attempts) > 0 else 0.0\n",
    "            },\n",
    "            'defensive_stats': {\n",
    "                'steals': stats.total_steals,\n",
    "                'blocks': stats.total_blocks,\n",
    "                'total_defensive_actions': stats.total_steals + stats.total_blocks\n",
    "            },\n",
    "            'playmaking': {\n",
    "                'assists': stats.total_assists\n",
    "            },\n",
    "            'detailed_events': [asdict(event) for event in events]\n",
    "        }\n",
    "\n",
    "print(\"âœ… Statistics Calculator defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 7. Main Processing Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasketballPOC:\n",
    "    \"\"\"Main processing pipeline orchestrator\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.video_processor = VideoProcessor(config)\n",
    "        self.gemini_analyzer = None\n",
    "        self.event_synthesizer = EventSynthesizer(config)\n",
    "        \n",
    "        # Initialize Gemini if API key available\n",
    "        if config.GEMINI_API_KEY:\n",
    "            self.gemini_analyzer = GeminiVideoAnalyzer(config.GEMINI_API_KEY, config.GEMINI_MODEL)\n",
    "    \n",
    "    def process_video(self, video_path: str, output_name: str = None) -> ProcessingResult:\n",
    "        \"\"\"Process complete basketball video\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # Validate inputs\n",
    "            if not Path(video_path).exists():\n",
    "                raise FileNotFoundError(f\"Video file not found: {video_path}\")\n",
    "            \n",
    "            if not self.gemini_analyzer:\n",
    "                raise ValueError(\"Gemini API key required for processing\")\n",
    "            \n",
    "            logger.info(f\"Starting processing: {video_path}\")\n",
    "            \n",
    "            # Get video info\n",
    "            video_info = self.video_processor.get_video_info(video_path)\n",
    "            logger.info(f\"Video info: {video_info}\")\n",
    "            \n",
    "            # Step 1: Segment video\n",
    "            logger.info(\"Step 1: Segmenting video...\")\n",
    "            segments = self.video_processor.segment_video(video_path)\n",
    "            \n",
    "            if not segments:\n",
    "                raise ValueError(\"Failed to create video segments\")\n",
    "            \n",
    "            # Step 2: Process each segment\n",
    "            logger.info(\"Step 2: Processing segments with Gemini...\")\n",
    "            all_events = []\n",
    "            \n",
    "            for segment in tqdm(segments, desc=\"Processing segments\"):\n",
    "                # Extract segment video\n",
    "                if self.video_processor.extract_segment(video_path, segment):\n",
    "                    # Analyze with Gemini\n",
    "                    raw_output = self.gemini_analyzer.analyze_video_segment(\n",
    "                        segment.file_path, segment.start_time, segment.end_time\n",
    "                    )\n",
    "                    \n",
    "                    # Parse events\n",
    "                    events = self.event_synthesizer.parse_gemini_output(raw_output, segment)\n",
    "                    all_events.extend(events)\n",
    "                    \n",
    "                    # Mark as processed\n",
    "                    segment.processed = True\n",
    "                    segment.events = events\n",
    "                    \n",
    "                    # Clean up segment file\n",
    "                    try:\n",
    "                        Path(segment.file_path).unlink()\n",
    "                    except:\n",
    "                        pass\n",
    "            \n",
    "            # Step 3: Deduplicate events\n",
    "            logger.info(\"Step 3: Deduplicating events...\")\n",
    "            all_events = self.event_synthesizer.deduplicate_events(all_events)\n",
    "            \n",
    "            # Step 4: Calculate statistics\n",
    "            logger.info(\"Step 4: Calculating statistics...\")\n",
    "            stats = StatisticsCalculator.calculate_statistics(all_events)\n",
    "            \n",
    "            # Step 5: Generate outputs\n",
    "            logger.info(\"Step 5: Generating outputs...\")\n",
    "            output_files = self._generate_outputs(\n",
    "                video_path, all_events, stats, video_info, output_name\n",
    "            )\n",
    "            \n",
    "            processing_time = time.time() - start_time\n",
    "            \n",
    "            # Create result\n",
    "            result = ProcessingResult(\n",
    "                video_path=video_path,\n",
    "                processing_time=processing_time,\n",
    "                total_segments=len(segments),\n",
    "                events=all_events,\n",
    "                statistics=stats,\n",
    "                output_files=output_files\n",
    "            )\n",
    "            \n",
    "            logger.info(f\"Processing completed in {processing_time:.2f} seconds\")\n",
    "            logger.info(f\"Detected {len(all_events)} events total\")\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing video: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def _generate_outputs(self, video_path: str, events: List[BasketballEvent], \n",
    "                         stats: GameStatistics, video_info: Dict, \n",
    "                         output_name: str = None) -> Dict[str, str]:\n",
    "        \"\"\"Generate all output files\"\"\"\n",
    "        if not output_name:\n",
    "            output_name = Path(video_path).stem\n",
    "        \n",
    "        output_files = {}\n",
    "        \n",
    "        # 1. JSON Report\n",
    "        json_path = self.config.OUTPUT_DIR / f\"{output_name}_analysis.json\"\n",
    "        report = StatisticsCalculator.generate_summary_report(stats, events, video_info)\n",
    "        \n",
    "        with open(json_path, 'w') as f:\n",
    "            json.dump(report, f, indent=2)\n",
    "        output_files['json_report'] = str(json_path)\n",
    "        \n",
    "        # 2. CSV Timeline\n",
    "        csv_path = self.config.OUTPUT_DIR / f\"{output_name}_timeline.csv\"\n",
    "        timeline_df = StatisticsCalculator.create_timeline_data(events)\n",
    "        if not timeline_df.empty:\n",
    "            timeline_df.to_csv(csv_path, index=False)\n",
    "            output_files['csv_timeline'] = str(csv_path)\n",
    "        \n",
    "        return output_files\n",
    "    \n",
    "    def print_summary(self, result: ProcessingResult):\n",
    "        \"\"\"Print processing summary\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"ðŸ€ BASKETBALL VIDEO ANALYSIS COMPLETE\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        print(f\"\\nðŸ“¹ Video: {Path(result.video_path).name}\")\n",
    "        print(f\"â±ï¸  Processing Time: {result.processing_time:.2f} seconds\")\n",
    "        print(f\"ðŸ“Š Total Events Detected: {len(result.events)}\")\n",
    "        print(f\"ðŸŽ¬ Video Segments Processed: {result.total_segments}\")\n",
    "        \n",
    "        print(\"\\nðŸ“ˆ GAME STATISTICS:\")\n",
    "        stats = result.statistics\n",
    "        print(f\"  2PT Shots: {stats.total_2pt_made}/{stats.total_2pt_attempts} ({stats.fg_percentage_2pt:.1f}%)\")\n",
    "        print(f\"  3PT Shots: {stats.total_3pt_made}/{stats.total_3pt_attempts} ({stats.fg_percentage_3pt:.1f}%)\")\n",
    "        print(f\"  Assists: {stats.total_assists}\")\n",
    "        print(f\"  Steals: {stats.total_steals}\")\n",
    "        print(f\"  Blocks: {stats.total_blocks}\")\n",
    "        \n",
    "        print(\"\\nðŸ“ OUTPUT FILES:\")\n",
    "        for file_type, file_path in result.output_files.items():\n",
    "            print(f\"  {file_type}: {file_path}\")\n",
    "        \n",
    "        if result.events:\n",
    "            print(\"\\nðŸŽ¯ EVENT TIMELINE:\")\n",
    "            for event in result.events[:10]:  # Show first 10 events\n",
    "                timestamp = f\"{int(event.timestamp//60):02d}:{int(event.timestamp%60):02d}\"\n",
    "                outcome = f\" ({event.outcome})\" if event.outcome else \"\"\n",
    "                print(f\"  {timestamp} - {event.event_type.upper()}{outcome}: {event.description[:50]}...\")\n",
    "            \n",
    "            if len(result.events) > 10:\n",
    "                print(f\"  ... and {len(result.events) - 10} more events\")\n",
    "\n",
    "# Initialize main processor\n",
    "basketball_poc = BasketballPOC(config)\n",
    "print(\"âœ… Basketball POC Pipeline initialized\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 8. Visualization and Demo Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Visualization and demo functions defined\n"
     ]
    }
   ],
   "source": [
    "def visualize_events(events: List[BasketballEvent]):\n",
    "    \"\"\"Create visualizations of detected events\"\"\"\n",
    "    if not events:\n",
    "        print(\"No events to visualize\")\n",
    "        return\n",
    "    \n",
    "    # Create timeline plot\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10))\n",
    "    \n",
    "    # Event timeline\n",
    "    event_types = [event.event_type for event in events]\n",
    "    timestamps = [event.timestamp for event in events]\n",
    "    \n",
    "    # Color map for events\n",
    "    color_map = {\n",
    "        '2pt_shot': 'blue',\n",
    "        '3pt_shot': 'green',\n",
    "        'assist': 'orange',\n",
    "        'steal': 'red',\n",
    "        'block': 'purple'\n",
    "    }\n",
    "    \n",
    "    colors = [color_map.get(et, 'gray') for et in event_types]\n",
    "    \n",
    "    ax1.scatter(timestamps, event_types, c=colors, alpha=0.7, s=100)\n",
    "    ax1.set_xlabel('Time (seconds)')\n",
    "    ax1.set_ylabel('Event Type')\n",
    "    ax1.set_title('Basketball Events Timeline')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Event count by type\n",
    "    event_counts = pd.Series(event_types).value_counts()\n",
    "    ax2.bar(event_counts.index, event_counts.values, \n",
    "            color=[color_map.get(et, 'gray') for et in event_counts.index])\n",
    "    ax2.set_xlabel('Event Type')\n",
    "    ax2.set_ylabel('Count')\n",
    "    ax2.set_title('Event Distribution')\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def run_validation_tests():\n",
    "    \"\"\"Run validation tests on the pipeline\"\"\"\n",
    "    print(\"ðŸ§ª Running validation tests...\")\n",
    "    \n",
    "    # Test 1: Configuration\n",
    "    assert config.SEGMENT_DURATION == 30, \"Segment duration should be 30 seconds\"\n",
    "    assert config.MAX_VIDEO_DURATION == 900, \"Max video duration should be 15 minutes\"\n",
    "    print(\"âœ… Configuration tests passed\")\n",
    "    \n",
    "    # Test 2: Event parsing\n",
    "    test_segment = VideoSegment(0, 0, 30, \"test.mp4\")\n",
    "    test_output = \"\"\"\n",
    "    TIMESTAMP: 5.2s\n",
    "    EVENT: 2-point shot\n",
    "    OUTCOME: made\n",
    "    DESCRIPTION: Player makes layup from close range\n",
    "    CONFIDENCE: 8\n",
    "    LOCATION: paint area\n",
    "    ---\n",
    "    \"\"\"\n",
    "    \n",
    "    events = event_synthesizer.parse_gemini_output(test_output, test_segment)\n",
    "    assert len(events) == 1, \"Should parse one event\"\n",
    "    assert events[0].event_type == '2pt_shot', \"Should be 2pt_shot\"\n",
    "    assert events[0].outcome == 'made', \"Should be made shot\"\n",
    "    print(\"âœ… Event parsing tests passed\")\n",
    "    \n",
    "    # Test 3: Statistics calculation\n",
    "    test_events = [\n",
    "        BasketballEvent('2pt_shot', 10, 1, 'test', 0.8, 'made'),\n",
    "        BasketballEvent('3pt_shot', 20, 1, 'test', 0.9, 'missed'),\n",
    "        BasketballEvent('assist', 30, 1, 'test', 0.7),\n",
    "    ]\n",
    "    \n",
    "    stats = StatisticsCalculator.calculate_statistics(test_events)\n",
    "    assert stats.total_2pt_made == 1, \"Should have 1 made 2pt shot\"\n",
    "    assert stats.total_3pt_attempts == 1, \"Should have 1 3pt attempt\"\n",
    "    assert stats.total_assists == 1, \"Should have 1 assist\"\n",
    "    print(\"âœ… Statistics calculation tests passed\")\n",
    "    \n",
    "    print(\"ðŸŽ‰ All validation tests passed!\")\n",
    "\n",
    "def display_analysis_dashboard():\n",
    "    \"\"\"Display comprehensive analysis dashboard\"\"\"\n",
    "    \n",
    "    # Find latest JSON report\n",
    "    json_files = list(config.OUTPUT_DIR.glob(\"*_analysis.json\"))\n",
    "    \n",
    "    if not json_files:\n",
    "        print(\"No analysis results found. Please process a video first.\")\n",
    "        return\n",
    "    \n",
    "    # Load latest result\n",
    "    latest_file = max(json_files, key=lambda x: x.stat().st_mtime)\n",
    "    \n",
    "    with open(latest_file, 'r') as f:\n",
    "        report = json.load(f)\n",
    "    \n",
    "    print(\"ðŸ“Š BASKETBALL ANALYSIS DASHBOARD\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Video info\n",
    "    video_info = report.get('video_info', {})\n",
    "    print(f\"\\nðŸ“¹ Video: {video_info.get('filename', 'Unknown')}\")\n",
    "    print(f\"â±ï¸  Duration: {video_info.get('duration', 0):.1f} seconds\")\n",
    "    print(f\"ðŸŽ¬ FPS: {video_info.get('fps', 0):.1f}\")\n",
    "    \n",
    "    # Processing summary\n",
    "    processing = report.get('processing_summary', {})\n",
    "    print(f\"\\nðŸ“ˆ Events Detected: {processing.get('total_events_detected', 0)}\")\n",
    "    print(f\"ðŸ• Processed: {processing.get('processing_timestamp', 'Unknown')}\")\n",
    "    \n",
    "    # Shooting stats\n",
    "    shooting = report.get('shooting_analysis', {})\n",
    "    print(\"\\nðŸ€ SHOOTING STATISTICS:\")\n",
    "    \n",
    "    fg2 = shooting.get('2pt_shooting', {})\n",
    "    print(f\"  2PT: {fg2.get('made', 0)}/{fg2.get('attempts', 0)} ({fg2.get('percentage', 0):.1f}%)\")\n",
    "    \n",
    "    fg3 = shooting.get('3pt_shooting', {})\n",
    "    print(f\"  3PT: {fg3.get('made', 0)}/{fg3.get('attempts', 0)} ({fg3.get('percentage', 0):.1f}%)\")\n",
    "    \n",
    "    print(f\"  Overall FG: {shooting.get('overall_fg_percentage', 0):.1f}%\")\n",
    "    \n",
    "    # Other stats\n",
    "    defensive = report.get('defensive_stats', {})\n",
    "    playmaking = report.get('playmaking', {})\n",
    "    \n",
    "    print(\"\\nâš¡ OTHER STATISTICS:\")\n",
    "    print(f\"  Assists: {playmaking.get('assists', 0)}\")\n",
    "    print(f\"  Steals: {defensive.get('steals', 0)}\")\n",
    "    print(f\"  Blocks: {defensive.get('blocks', 0)}\")\n",
    "    \n",
    "    # Event details\n",
    "    events = report.get('detailed_events', [])\n",
    "    if events:\n",
    "        print(\"\\nðŸŽ¯ RECENT EVENTS:\")\n",
    "        for i, event in enumerate(events[:5]):\n",
    "            timestamp = event.get('timestamp', 0)\n",
    "            mins, secs = divmod(timestamp, 60)\n",
    "            event_type = event.get('event_type', '').upper()\n",
    "            outcome = event.get('outcome', '')\n",
    "            outcome_str = f\" ({outcome.upper()})\" if outcome else \"\"\n",
    "            description = event.get('description', '')[:40] + \"...\"\n",
    "            \n",
    "            print(f\"  {int(mins):02d}:{int(secs):02d} - {event_type}{outcome_str}\")\n",
    "            print(f\"    {description}\")\n",
    "\n",
    "print(\"âœ… Visualization and demo functions defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 9. Usage Examples and Demo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-01 18:17:46,357 - INFO - Parsed 1 events from segment 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Running validation tests...\n",
      "âœ… Configuration tests passed\n",
      "âœ… Event parsing tests passed\n",
      "âœ… Statistics calculation tests passed\n",
      "ðŸŽ‰ All validation tests passed!\n"
     ]
    }
   ],
   "source": [
    "# Run validation tests\n",
    "run_validation_tests()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### ðŸš€ Process Your Basketball Video\n",
    "\n",
    "To process a basketball video, run the cell below after setting your video path:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¹ Processing video: data/sample_basketball_video_3.mp4\n",
      "âŒ Error processing video: name 'basketball_poc' is not defined\n"
     ]
    }
   ],
   "source": [
    "# MAIN PROCESSING EXAMPLE\n",
    "# Replace with your video path\n",
    "VIDEO_PATH = \"data/sample_basketball_video_3.mp4\"\n",
    "\n",
    "# Check if video file exists\n",
    "if Path(VIDEO_PATH).exists():\n",
    "    print(f\"ðŸ“¹ Processing video: {VIDEO_PATH}\")\n",
    "    \n",
    "    # Process the video\n",
    "    try:\n",
    "        result = basketball_poc.process_video(VIDEO_PATH)\n",
    "        \n",
    "        # Print summary\n",
    "        basketball_poc.print_summary(result)\n",
    "        \n",
    "        # Visualize events\n",
    "        if result.events:\n",
    "            visualize_events(result.events)\n",
    "        \n",
    "        print(\"\\nðŸŽ‰ Processing completed successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error processing video: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(f\"âŒ Video file not found: {VIDEO_PATH}\")\n",
    "    print(\"ðŸ“ Please update VIDEO_PATH with your basketball video file\")\n",
    "    print(\"\\nðŸ’¡ To test the system:\")\n",
    "    print(\"1. Download a basketball video (15 minutes or less)\")\n",
    "    print(\"2. Place it in the 'data/' directory\")\n",
    "    print(\"3. Update VIDEO_PATH variable above\")\n",
    "    print(\"4. Ensure your GEMINI_API_KEY is set\")\n",
    "    print(\"5. Run this cell again\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### ðŸ“Š Analysis Dashboard\n",
    "\n",
    "View detailed analysis of the last processed video:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š BASKETBALL ANALYSIS DASHBOARD\n",
      "==================================================\n",
      "\n",
      "ðŸ“¹ Video: sample_baseketball_video.mp4\n",
      "â±ï¸  Duration: 130.9 seconds\n",
      "ðŸŽ¬ FPS: 60.0\n",
      "\n",
      "ðŸ“ˆ Events Detected: 20\n",
      "ðŸ• Processed: 2025-07-31T22:10:12.921912\n",
      "\n",
      "ðŸ€ SHOOTING STATISTICS:\n",
      "  2PT: 7/8 (87.5%)\n",
      "  3PT: 0/0 (0.0%)\n",
      "  Overall FG: 87.5%\n",
      "\n",
      "âš¡ OTHER STATISTICS:\n",
      "  Assists: 3\n",
      "  Steals: 2\n",
      "  Blocks: 2\n",
      "\n",
      "ðŸŽ¯ RECENT EVENTS:\n",
      "  00:01 - 2PT_SHOT (MADE)\n",
      "    LeBron James drives into the paint from ...\n",
      "  00:07 - STEAL\n",
      "    A Lakers pass is deflected by Nikola Jok...\n",
      "  00:10 - 2PT_SHOT (MADE)\n",
      "    On the ensuing fast break after the stea...\n",
      "  00:15 - 2PT_SHOT (MADE)\n",
      "    With the shot clock about to expire, LeB...\n",
      "  00:25 - BLOCK\n",
      "    A Houston Rockets player drives for a la...\n"
     ]
    }
   ],
   "source": [
    "# Run dashboard\n",
    "display_analysis_dashboard()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
