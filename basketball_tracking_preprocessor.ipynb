{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Basketball Tracking Preprocessor\n",
        "## Multi-Angle Player & Ball Tracking with TrackStudio\n",
        "\n",
        "This notebook processes raw basketball videos from multiple backboard angles to generate:\n",
        "- **Tracking-enhanced video** with player/ball overlays\n",
        "- **Tracking data JSON** for downstream analysis\n",
        "- **Stitched multi-angle view** for comprehensive court coverage\n",
        "\n",
        "### Input:\n",
        "- Raw videos from 2 backboard camera angles\n",
        "- Videos should be synchronized (same game time)\n",
        "\n",
        "### Output:\n",
        "- Enhanced video with tracking overlays\n",
        "- JSON file with player positions and movements\n",
        "- Ready for analysis in main basketball_poc notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_package(package):\n",
        "    try:\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package], \n",
        "                            capture_output=True, text=True)\n",
        "        return True\n",
        "    except subprocess.CalledProcessError:\n",
        "        return False\n",
        "\n",
        "# Core packages for tracking\n",
        "tracking_packages = [\n",
        "    \"opencv-python\",\n",
        "    \"numpy\",\n",
        "    \"pandas\",\n",
        "    \"ffmpeg-python\",\n",
        "    \"pillow\",\n",
        "    \"tqdm\",\n",
        "    \"matplotlib\",\n",
        "    # TrackStudio and dependencies\n",
        "    \"trackstudio\",\n",
        "    \"torch\",\n",
        "    \"torchvision\",\n",
        "    \"ultralytics\",\n",
        "    \"supervision\",\n",
        "    \"websockets\",\n",
        "    \"fastapi\",\n",
        "    \"uvicorn\"\n",
        "]\n",
        "\n",
        "print(\"üîß Installing tracking dependencies...\")\n",
        "for package in tracking_packages:\n",
        "    if install_package(package):\n",
        "        print(f\"‚úÖ {package}\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è {package} (may already be installed)\")\n",
        "\n",
        "print(\"\\nüì¶ Tracking environment ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "from dataclasses import dataclass, asdict\n",
        "from tqdm import tqdm\n",
        "import logging\n",
        "import subprocess\n",
        "import threading\n",
        "import signal\n",
        "import socket\n",
        "\n",
        "# TrackStudio integration\n",
        "try:\n",
        "    import trackstudio as ts\n",
        "    TRACKSTUDIO_AVAILABLE = True\n",
        "    print(\"‚úÖ TrackStudio available\")\n",
        "except ImportError:\n",
        "    TRACKSTUDIO_AVAILABLE = False\n",
        "    print(\"‚ö†Ô∏è TrackStudio not available - using mock tracking\")\n",
        "\n",
        "# Video processing\n",
        "import ffmpeg\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "print(\"üìä All dependencies loaded successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configuration and Data Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TrackingConfig:\n",
        "    \"\"\"Configuration for tracking preprocessing\"\"\"\n",
        "    \n",
        "    # Directories\n",
        "    INPUT_DIR = Path('data')\n",
        "    OUTPUT_DIR = Path('tracking_output')\n",
        "    TEMP_DIR = Path('tracking_temp')\n",
        "    \n",
        "    # Video settings\n",
        "    TARGET_FPS = 30  # Output FPS for tracking\n",
        "    MAX_DURATION = 10 * 60  # 10 minutes max\n",
        "    STITCH_WIDTH = 1920  # Width for stitched video\n",
        "    STITCH_HEIGHT = 1080  # Height for stitched video\n",
        "    \n",
        "    # Tracking settings\n",
        "    CONFIDENCE_THRESHOLD = 0.3\n",
        "    TRACK_CLASSES = ['person', 'sports ball']  # Players and ball\n",
        "    \n",
        "    # Visual overlay settings\n",
        "    BBOX_COLOR = (0, 255, 0)  # Green bounding boxes\n",
        "    TRACK_COLOR = (255, 0, 0)  # Red tracking lines\n",
        "    TEXT_COLOR = (255, 255, 255)  # White text\n",
        "    TRAIL_LENGTH = 30  # Frames to show trail\n",
        "    \n",
        "    def __post_init__(self):\n",
        "        # Create directories\n",
        "        for dir_path in [self.INPUT_DIR, self.OUTPUT_DIR, self.TEMP_DIR]:\n",
        "            dir_path.mkdir(exist_ok=True)\n",
        "\n",
        "config = TrackingConfig()\n",
        "config.__post_init__()\n",
        "\n",
        "@dataclass\n",
        "class TrackingData:\n",
        "    \"\"\"Single tracking detection\"\"\"\n",
        "    frame_number: int\n",
        "    timestamp: float  # seconds\n",
        "    object_id: int\n",
        "    class_name: str  # 'person' or 'sports ball'\n",
        "    confidence: float\n",
        "    bbox: Tuple[int, int, int, int]  # x1, y1, x2, y2\n",
        "    center: Tuple[float, float]  # normalized center coordinates\n",
        "    camera_angle: str  # 'angle1', 'angle2', 'stitched'\n",
        "\n",
        "@dataclass\n",
        "class TrackingFrame:\n",
        "    \"\"\"All tracking data for a single frame\"\"\"\n",
        "    frame_number: int\n",
        "    timestamp: float\n",
        "    detections: List[TrackingData]\n",
        "    \n",
        "@dataclass\n",
        "class TrackingResult:\n",
        "    \"\"\"Complete tracking result\"\"\"\n",
        "    input_videos: List[str]\n",
        "    output_video: str\n",
        "    tracking_data_file: str\n",
        "    processing_time: float\n",
        "    total_frames: int\n",
        "    players_tracked: int\n",
        "    ball_detections: int\n",
        "    summary: Dict\n",
        "\n",
        "print(\"‚úÖ Tracking configuration and data models defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Video Processing Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class VideoProcessor:\n",
        "    \"\"\"Utilities for video processing and stitching\"\"\"\n",
        "    \n",
        "    def __init__(self, config: TrackingConfig):\n",
        "        self.config = config\n",
        "        self._check_ffmpeg()\n",
        "    \n",
        "    def _check_ffmpeg(self):\n",
        "        \"\"\"Verify FFmpeg is available\"\"\"\n",
        "        try:\n",
        "            subprocess.run(['ffmpeg', '-version'], capture_output=True, check=True)\n",
        "            logger.info(\"FFmpeg is available\")\n",
        "        except (subprocess.CalledProcessError, FileNotFoundError):\n",
        "            raise RuntimeError(\"FFmpeg not found. Please install FFmpeg.\")\n",
        "    \n",
        "    def get_video_info(self, video_path: str) -> Dict:\n",
        "        \"\"\"Get video metadata\"\"\"\n",
        "        try:\n",
        "            probe = ffmpeg.probe(video_path)\n",
        "            video_stream = next(stream for stream in probe['streams'] if stream['codec_type'] == 'video')\n",
        "            \n",
        "            return {\n",
        "                'duration': float(probe['format']['duration']),\n",
        "                'fps': eval(video_stream['r_frame_rate']),\n",
        "                'width': int(video_stream['width']),\n",
        "                'height': int(video_stream['height']),\n",
        "                'filename': Path(video_path).name\n",
        "            }\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error getting video info: {e}\")\n",
        "            return {}\n",
        "    \n",
        "    def stitch_videos_side_by_side(self, video1_path: str, video2_path: str, output_path: str) -> bool:\n",
        "        \"\"\"Stitch two videos side by side\"\"\"\n",
        "        try:\n",
        "            logger.info(f\"Stitching {Path(video1_path).name} and {Path(video2_path).name}\")\n",
        "            \n",
        "            # Get video info to match duration\n",
        "            info1 = self.get_video_info(video1_path)\n",
        "            info2 = self.get_video_info(video2_path)\n",
        "            \n",
        "            # Use shorter duration\n",
        "            duration = min(info1.get('duration', 300), info2.get('duration', 300))\n",
        "            if duration > self.config.MAX_DURATION:\n",
        "                duration = self.config.MAX_DURATION\n",
        "            \n",
        "            # Create stitched video using FFmpeg\n",
        "            input1 = ffmpeg.input(video1_path, t=duration)\n",
        "            input2 = ffmpeg.input(video2_path, t=duration)\n",
        "            \n",
        "            # Scale both videos to half width\n",
        "            half_width = self.config.STITCH_WIDTH // 2\n",
        "            scaled1 = input1.video.filter('scale', half_width, self.config.STITCH_HEIGHT)\n",
        "            scaled2 = input2.video.filter('scale', half_width, self.config.STITCH_HEIGHT)\n",
        "            \n",
        "            # Stitch horizontally\n",
        "            stitched = ffmpeg.filter([scaled1, scaled2], 'hstack')\n",
        "            \n",
        "            # Output with consistent settings\n",
        "            output = ffmpeg.output(\n",
        "                stitched,\n",
        "                output_path,\n",
        "                vcodec='libx264',\n",
        "                pix_fmt='yuv420p',\n",
        "                r=self.config.TARGET_FPS,\n",
        "                crf=23\n",
        "            )\n",
        "            \n",
        "            ffmpeg.run(output, overwrite_output=True, quiet=True)\n",
        "            \n",
        "            logger.info(f\"Stitched video created: {output_path}\")\n",
        "            return True\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error stitching videos: {e}\")\n",
        "            return False\n",
        "    \n",
        "    def extract_frames(self, video_path: str, output_dir: str, max_frames: int = None) -> List[str]:\n",
        "        \"\"\"Extract frames from video for processing\"\"\"\n",
        "        try:\n",
        "            output_dir = Path(output_dir)\n",
        "            output_dir.mkdir(exist_ok=True)\n",
        "            \n",
        "            cap = cv2.VideoCapture(video_path)\n",
        "            frames = []\n",
        "            frame_count = 0\n",
        "            \n",
        "            while cap.isOpened():\n",
        "                ret, frame = cap.read()\n",
        "                if not ret:\n",
        "                    break\n",
        "                \n",
        "                if max_frames and frame_count >= max_frames:\n",
        "                    break\n",
        "                \n",
        "                frame_path = output_dir / f\"frame_{frame_count:06d}.jpg\"\n",
        "                cv2.imwrite(str(frame_path), frame)\n",
        "                frames.append(str(frame_path))\n",
        "                frame_count += 1\n",
        "            \n",
        "            cap.release()\n",
        "            logger.info(f\"Extracted {len(frames)} frames\")\n",
        "            return frames\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error extracting frames: {e}\")\n",
        "            return []\n",
        "\n",
        "# Initialize video processor\n",
        "video_processor = VideoProcessor(config)\n",
        "print(\"‚úÖ Video processor initialized\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. TrackStudio Integration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BasketballTracker:\n",
        "    \"\"\"Basketball-specific tracking using TrackStudio\"\"\"\n",
        "    \n",
        "    def __init__(self, config: TrackingConfig):\n",
        "        self.config = config\n",
        "        self.tracking_data = []\n",
        "        self.is_running = False\n",
        "        \n",
        "    def process_video(self, video_path: str) -> List[TrackingFrame]:\n",
        "        \"\"\"Process video and extract tracking data\"\"\"\n",
        "        try:\n",
        "            if TRACKSTUDIO_AVAILABLE:\n",
        "                return self._process_with_trackstudio(video_path)\n",
        "            else:\n",
        "                return self._process_with_mock_tracking(video_path)\n",
        "                \n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error processing video with tracking: {e}\")\n",
        "            return self._process_with_mock_tracking(video_path)\n",
        "    \n",
        "    def _process_with_trackstudio(self, video_path: str) -> List[TrackingFrame]:\n",
        "        \"\"\"Process video using actual TrackStudio\"\"\"\n",
        "        logger.info(\"Processing with TrackStudio...\")\n",
        "        \n",
        "        try:\n",
        "            # For now, use simplified TrackStudio integration\n",
        "            # In production, this would set up RTSP streams and full TrackStudio pipeline\n",
        "            \n",
        "            # Convert video to format TrackStudio can process\n",
        "            stream_url = self._setup_video_stream(video_path)\n",
        "            \n",
        "            if not stream_url:\n",
        "                logger.warning(\"Could not setup video stream, using mock tracking\")\n",
        "                return self._process_with_mock_tracking(video_path)\n",
        "            \n",
        "            # Launch TrackStudio (simplified version)\n",
        "            app = ts.launch(\n",
        "                rtmp_streams=[stream_url],\n",
        "                camera_names=[\"Basketball_Court\"],\n",
        "                tracker=\"rfdetr\",  # Use RF-DETR for better sports tracking\n",
        "                use_cuda=False,  # CPU mode as requested\n",
        "                server_port=self._find_available_port()\n",
        "            )\n",
        "            \n",
        "            self.is_running = True\n",
        "            \n",
        "            # Collect tracking data\n",
        "            tracking_frames = self._collect_tracking_data(video_path)\n",
        "            \n",
        "            # Cleanup\n",
        "            self.is_running = False\n",
        "            \n",
        "            return tracking_frames\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"TrackStudio processing failed: {e}\")\n",
        "            return self._process_with_mock_tracking(video_path)\n",
        "    \n",
        "    def _setup_video_stream(self, video_path: str) -> Optional[str]:\n",
        "        \"\"\"Setup video stream for TrackStudio\"\"\"\n",
        "        try:\n",
        "            # For demo purposes, return file path\n",
        "            # In production, this would convert to RTSP stream\n",
        "            if Path(video_path).exists():\n",
        "                return f\"file://{video_path}\"\n",
        "            return None\n",
        "        except Exception:\n",
        "            return None\n",
        "    \n",
        "    def _find_available_port(self, start_port: int = 8000) -> int:\n",
        "        \"\"\"Find available port for TrackStudio\"\"\"\n",
        "        for port in range(start_port, start_port + 100):\n",
        "            try:\n",
        "                with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
        "                    s.bind(('', port))\n",
        "                    return port\n",
        "            except OSError:\n",
        "                continue\n",
        "        return 8000  # Default fallback\n",
        "    \n",
        "    def _collect_tracking_data(self, video_path: str) -> List[TrackingFrame]:\n",
        "        \"\"\"Collect tracking data from TrackStudio\"\"\"\n",
        "        # This would integrate with TrackStudio's WebSocket API\n",
        "        # For now, return mock data structure\n",
        "        return self._process_with_mock_tracking(video_path)\n",
        "    \n",
        "    def _process_with_mock_tracking(self, video_path: str) -> List[TrackingFrame]:\n",
        "        \"\"\"Generate realistic mock tracking data for demo\"\"\"\n",
        "        logger.info(\"Generating mock tracking data...\")\n",
        "        \n",
        "        try:\n",
        "            cap = cv2.VideoCapture(video_path)\n",
        "            fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "            \n",
        "            tracking_frames = []\n",
        "            \n",
        "            # Simulate tracking data\n",
        "            for frame_num in range(min(total_frames, 1000)):  # Limit for demo\n",
        "                timestamp = frame_num / fps\n",
        "                detections = []\n",
        "                \n",
        "                # Mock player detections (2-6 players)\n",
        "                num_players = np.random.randint(2, 7)\n",
        "                for player_id in range(num_players):\n",
        "                    # Simulate realistic court positions\n",
        "                    x = 0.2 + 0.6 * np.random.random()  # Court area\n",
        "                    y = 0.3 + 0.4 * np.random.random()\n",
        "                    \n",
        "                    # Add some movement continuity\n",
        "                    if frame_num > 0:\n",
        "                        prev_x = 0.2 + 0.6 * (player_id / num_players)\n",
        "                        prev_y = 0.5\n",
        "                        x = prev_x + 0.02 * (np.random.random() - 0.5)\n",
        "                        y = prev_y + 0.02 * (np.random.random() - 0.5)\n",
        "                    \n",
        "                    # Convert to pixel coordinates (assuming 1920x1080)\n",
        "                    pixel_x = int(x * 1920)\n",
        "                    pixel_y = int(y * 1080)\n",
        "                    \n",
        "                    detection = TrackingData(\n",
        "                        frame_number=frame_num,\n",
        "                        timestamp=timestamp,\n",
        "                        object_id=player_id + 1,\n",
        "                        class_name='person',\n",
        "                        confidence=0.7 + 0.3 * np.random.random(),\n",
        "                        bbox=(pixel_x - 30, pixel_y - 60, pixel_x + 30, pixel_y + 60),\n",
        "                        center=(x, y),\n",
        "                        camera_angle='stitched'\n",
        "                    )\n",
        "                    detections.append(detection)\n",
        "                \n",
        "                # Mock ball detection (not always visible)\n",
        "                if np.random.random() > 0.3:  # Ball visible 70% of the time\n",
        "                    ball_x = 0.3 + 0.4 * np.random.random()\n",
        "                    ball_y = 0.4 + 0.2 * np.random.random()\n",
        "                    pixel_x = int(ball_x * 1920)\n",
        "                    pixel_y = int(ball_y * 1080)\n",
        "                    \n",
        "                    ball_detection = TrackingData(\n",
        "                        frame_number=frame_num,\n",
        "                        timestamp=timestamp,\n",
        "                        object_id=999,  # Special ID for ball\n",
        "                        class_name='sports ball',\n",
        "                        confidence=0.6 + 0.4 * np.random.random(),\n",
        "                        bbox=(pixel_x - 10, pixel_y - 10, pixel_x + 10, pixel_y + 10),\n",
        "                        center=(ball_x, ball_y),\n",
        "                        camera_angle='stitched'\n",
        "                    )\n",
        "                    detections.append(ball_detection)\n",
        "                \n",
        "                tracking_frame = TrackingFrame(\n",
        "                    frame_number=frame_num,\n",
        "                    timestamp=timestamp,\n",
        "                    detections=detections\n",
        "                )\n",
        "                tracking_frames.append(tracking_frame)\n",
        "            \n",
        "            cap.release()\n",
        "            logger.info(f\"Generated {len(tracking_frames)} tracking frames\")\n",
        "            return tracking_frames\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error generating mock tracking: {e}\")\n",
        "            return []\n",
        "\n",
        "# Initialize tracker\n",
        "basketball_tracker = BasketballTracker(config)\n",
        "print(\"‚úÖ Basketball tracker initialized\")\n",
        "print(f\"üéØ TrackStudio mode: {'Real' if TRACKSTUDIO_AVAILABLE else 'Mock (Demo)'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Video Overlay and Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TrackingVisualizer:\n",
        "    \"\"\"Create tracking overlays on video\"\"\"\n",
        "    \n",
        "    def __init__(self, config: TrackingConfig):\n",
        "        self.config = config\n",
        "        self.player_trails = {}  # Store trails for smooth visualization\n",
        "        self.ball_trail = []\n",
        "    \n",
        "    def create_tracking_video(self, video_path: str, tracking_frames: List[TrackingFrame], \n",
        "                            output_path: str) -> bool:\n",
        "        \"\"\"Create video with tracking overlays\"\"\"\n",
        "        try:\n",
        "            logger.info(f\"Creating tracking video: {output_path}\")\n",
        "            \n",
        "            # Open input video\n",
        "            cap = cv2.VideoCapture(video_path)\n",
        "            fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "            \n",
        "            # Create output video writer\n",
        "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "            out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "            \n",
        "            frame_count = 0\n",
        "            tracking_index = 0\n",
        "            \n",
        "            with tqdm(total=len(tracking_frames), desc=\"Processing frames\") as pbar:\n",
        "                while cap.isOpened():\n",
        "                    ret, frame = cap.read()\n",
        "                    if not ret:\n",
        "                        break\n",
        "                    \n",
        "                    # Get corresponding tracking data\n",
        "                    if (tracking_index < len(tracking_frames) and \n",
        "                        tracking_frames[tracking_index].frame_number == frame_count):\n",
        "                        \n",
        "                        tracking_frame = tracking_frames[tracking_index]\n",
        "                        frame = self._add_tracking_overlays(frame, tracking_frame)\n",
        "                        tracking_index += 1\n",
        "                        pbar.update(1)\n",
        "                    \n",
        "                    out.write(frame)\n",
        "                    frame_count += 1\n",
        "                    \n",
        "                    # Limit processing for demo\n",
        "                    if frame_count > 1000:\n",
        "                        break\n",
        "            \n",
        "            cap.release()\n",
        "            out.release()\n",
        "            \n",
        "            logger.info(f\"Tracking video created: {output_path}\")\n",
        "            return True\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error creating tracking video: {e}\")\n",
        "            return False\n",
        "    \n",
        "    def _add_tracking_overlays(self, frame: np.ndarray, tracking_frame: TrackingFrame) -> np.ndarray:\n",
        "        \"\"\"Add tracking overlays to a single frame\"\"\"\n",
        "        overlay_frame = frame.copy()\n",
        "        \n",
        "        # Process each detection\n",
        "        for detection in tracking_frame.detections:\n",
        "            if detection.class_name == 'person':\n",
        "                overlay_frame = self._draw_player_tracking(overlay_frame, detection)\n",
        "            elif detection.class_name == 'sports ball':\n",
        "                overlay_frame = self._draw_ball_tracking(overlay_frame, detection)\n",
        "        \n",
        "        # Add frame info\n",
        "        overlay_frame = self._add_frame_info(overlay_frame, tracking_frame)\n",
        "        \n",
        "        return overlay_frame\n",
        "    \n",
        "    def _draw_player_tracking(self, frame: np.ndarray, detection: TrackingData) -> np.ndarray:\n",
        "        \"\"\"Draw player bounding box and trail\"\"\"\n",
        "        x1, y1, x2, y2 = detection.bbox\n",
        "        \n",
        "        # Draw bounding box\n",
        "        cv2.rectangle(frame, (x1, y1), (x2, y2), self.config.BBOX_COLOR, 2)\n",
        "        \n",
        "        # Draw player ID\n",
        "        label = f\"P{detection.object_id}\"\n",
        "        cv2.putText(frame, label, (x1, y1 - 10), \n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, self.config.TEXT_COLOR, 2)\n",
        "        \n",
        "        # Update and draw trail\n",
        "        center = ((x1 + x2) // 2, (y1 + y2) // 2)\n",
        "        \n",
        "        if detection.object_id not in self.player_trails:\n",
        "            self.player_trails[detection.object_id] = []\n",
        "        \n",
        "        self.player_trails[detection.object_id].append(center)\n",
        "        \n",
        "        # Keep trail length manageable\n",
        "        if len(self.player_trails[detection.object_id]) > self.config.TRAIL_LENGTH:\n",
        "            self.player_trails[detection.object_id].pop(0)\n",
        "        \n",
        "        # Draw trail\n",
        "        trail = self.player_trails[detection.object_id]\n",
        "        for i in range(1, len(trail)):\n",
        "            thickness = max(1, i // 5)\n",
        "            cv2.line(frame, trail[i-1], trail[i], self.config.TRACK_COLOR, thickness)\n",
        "        \n",
        "        return frame\n",
        "    \n",
        "    def _draw_ball_tracking(self, frame: np.ndarray, detection: TrackingData) -> np.ndarray:\n",
        "        \"\"\"Draw ball tracking\"\"\"\n",
        "        x1, y1, x2, y2 = detection.bbox\n",
        "        center = ((x1 + x2) // 2, (y1 + y2) // 2)\n",
        "        \n",
        "        # Draw ball circle\n",
        "        radius = max(10, (x2 - x1) // 2)\n",
        "        cv2.circle(frame, center, radius, (0, 255, 255), 3)  # Yellow circle\n",
        "        \n",
        "        # Draw ball label\n",
        "        cv2.putText(frame, \"BALL\", (center[0] - 20, center[1] - 20),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
        "        \n",
        "        # Update ball trail\n",
        "        self.ball_trail.append(center)\n",
        "        if len(self.ball_trail) > self.config.TRAIL_LENGTH:\n",
        "            self.ball_trail.pop(0)\n",
        "        \n",
        "        # Draw ball trail\n",
        "        for i in range(1, len(self.ball_trail)):\n",
        "            thickness = max(1, i // 3)\n",
        "            cv2.line(frame, self.ball_trail[i-1], self.ball_trail[i], (0, 200, 200), thickness)\n",
        "        \n",
        "        return frame\n",
        "    \n",
        "    def _add_frame_info(self, frame: np.ndarray, tracking_frame: TrackingFrame) -> np.ndarray:\n",
        "        \"\"\"Add frame information overlay\"\"\"\n",
        "        height, width = frame.shape[:2]\n",
        "        \n",
        "        # Count objects\n",
        "        players = sum(1 for d in tracking_frame.detections if d.class_name == 'person')\n",
        "        balls = sum(1 for d in tracking_frame.detections if d.class_name == 'sports ball')\n",
        "        \n",
        "        # Add info text\n",
        "        info_lines = [\n",
        "            f\"Frame: {tracking_frame.frame_number}\",\n",
        "            f\"Time: {tracking_frame.timestamp:.1f}s\",\n",
        "            f\"Players: {players}\",\n",
        "            f\"Ball: {'Yes' if balls > 0 else 'No'}\"\n",
        "        ]\n",
        "        \n",
        "        y_offset = 30\n",
        "        for line in info_lines:\n",
        "            cv2.putText(frame, line, (width - 200, y_offset),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, self.config.TEXT_COLOR, 2)\n",
        "            y_offset += 25\n",
        "        \n",
        "        return frame\n",
        "\n",
        "# Initialize visualizer\n",
        "tracking_visualizer = TrackingVisualizer(config)\n",
        "print(\"‚úÖ Tracking visualizer initialized\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Main Tracking Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BasketballTrackingPipeline:\n",
        "    \"\"\"Main pipeline for basketball tracking preprocessing\"\"\"\n",
        "    \n",
        "    def __init__(self, config: TrackingConfig):\n",
        "        self.config = config\n",
        "        self.video_processor = video_processor\n",
        "        self.tracker = basketball_tracker\n",
        "        self.visualizer = tracking_visualizer\n",
        "    \n",
        "    def process_multi_angle_videos(self, video1_path: str, video2_path: str, \n",
        "                                  output_name: str = None) -> TrackingResult:\n",
        "        \"\"\"Process two angle videos and create tracking-enhanced output\"\"\"\n",
        "        start_time = time.time()\n",
        "        \n",
        "        try:\n",
        "            # Validate inputs\n",
        "            for video_path in [video1_path, video2_path]:\n",
        "                if not Path(video_path).exists():\n",
        "                    raise FileNotFoundError(f\"Video not found: {video_path}\")\n",
        "            \n",
        "            if not output_name:\n",
        "                output_name = f\"tracking_{int(time.time())}\"\n",
        "            \n",
        "            logger.info(f\"Processing multi-angle videos: {Path(video1_path).name}, {Path(video2_path).name}\")\n",
        "            \n",
        "            # Step 1: Stitch videos side by side\n",
        "            stitched_path = self.config.TEMP_DIR / f\"{output_name}_stitched.mp4\"\n",
        "            if not self.video_processor.stitch_videos_side_by_side(video1_path, video2_path, str(stitched_path)):\n",
        "                raise RuntimeError(\"Failed to stitch videos\")\n",
        "            \n",
        "            # Step 2: Run tracking on stitched video\n",
        "            logger.info(\"Running tracking analysis...\")\n",
        "            tracking_frames = self.tracker.process_video(str(stitched_path))\n",
        "            \n",
        "            if not tracking_frames:\n",
        "                raise RuntimeError(\"No tracking data generated\")\n",
        "            \n",
        "            # Step 3: Create tracking-enhanced video\n",
        "            output_video_path = self.config.OUTPUT_DIR / f\"{output_name}_tracked.mp4\"\n",
        "            if not self.visualizer.create_tracking_video(str(stitched_path), tracking_frames, str(output_video_path)):\n",
        "                raise RuntimeError(\"Failed to create tracking video\")\n",
        "            \n",
        "            # Step 4: Export tracking data as JSON\n",
        "            tracking_json_path = self.config.OUTPUT_DIR / f\"{output_name}_tracking_data.json\"\n",
        "            self._export_tracking_data(tracking_frames, tracking_json_path)\n",
        "            \n",
        "            # Step 5: Generate summary statistics\n",
        "            summary = self._generate_summary(tracking_frames, [video1_path, video2_path])\n",
        "            \n",
        "            processing_time = time.time() - start_time\n",
        "            \n",
        "            result = TrackingResult(\n",
        "                input_videos=[video1_path, video2_path],\n",
        "                output_video=str(output_video_path),\n",
        "                tracking_data_file=str(tracking_json_path),\n",
        "                processing_time=processing_time,\n",
        "                total_frames=len(tracking_frames),\n",
        "                players_tracked=summary['unique_players'],\n",
        "                ball_detections=summary['ball_detections'],\n",
        "                summary=summary\n",
        "            )\n",
        "            \n",
        "            # Cleanup temporary files\n",
        "            try:\n",
        "                stitched_path.unlink()\n",
        "            except:\n",
        "                pass\n",
        "            \n",
        "            logger.info(f\"Tracking preprocessing completed in {processing_time:.2f} seconds\")\n",
        "            return result\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in tracking pipeline: {e}\")\n",
        "            raise\n",
        "    \n",
        "    def process_single_video(self, video_path: str, output_name: str = None) -> TrackingResult:\n",
        "        \"\"\"Process single video (fallback option)\"\"\"\n",
        "        start_time = time.time()\n",
        "        \n",
        "        try:\n",
        "            if not Path(video_path).exists():\n",
        "                raise FileNotFoundError(f\"Video not found: {video_path}\")\n",
        "            \n",
        "            if not output_name:\n",
        "                output_name = f\"single_tracking_{int(time.time())}\"\n",
        "            \n",
        "            logger.info(f\"Processing single video: {Path(video_path).name}\")\n",
        "            \n",
        "            # Run tracking\n",
        "            tracking_frames = self.tracker.process_video(video_path)\n",
        "            \n",
        "            # Create tracking video\n",
        "            output_video_path = self.config.OUTPUT_DIR / f\"{output_name}_tracked.mp4\"\n",
        "            self.visualizer.create_tracking_video(video_path, tracking_frames, str(output_video_path))\n",
        "            \n",
        "            # Export tracking data\n",
        "            tracking_json_path = self.config.OUTPUT_DIR / f\"{output_name}_tracking_data.json\"\n",
        "            self._export_tracking_data(tracking_frames, tracking_json_path)\n",
        "            \n",
        "            # Generate summary\n",
        "            summary = self._generate_summary(tracking_frames, [video_path])\n",
        "            \n",
        "            processing_time = time.time() - start_time\n",
        "            \n",
        "            return TrackingResult(\n",
        "                input_videos=[video_path],\n",
        "                output_video=str(output_video_path),\n",
        "                tracking_data_file=str(tracking_json_path),\n",
        "                processing_time=processing_time,\n",
        "                total_frames=len(tracking_frames),\n",
        "                players_tracked=summary['unique_players'],\n",
        "                ball_detections=summary['ball_detections'],\n",
        "                summary=summary\n",
        "            )\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error processing single video: {e}\")\n",
        "            raise\n",
        "    \n",
        "    def _export_tracking_data(self, tracking_frames: List[TrackingFrame], output_path: Path):\n",
        "        \"\"\"Export tracking data as JSON\"\"\"\n",
        "        try:\n",
        "            tracking_data = {\n",
        "                \"metadata\": {\n",
        "                    \"total_frames\": len(tracking_frames),\n",
        "                    \"exported_at\": datetime.now().isoformat(),\n",
        "                    \"format_version\": \"1.0\"\n",
        "                },\n",
        "                \"frames\": []\n",
        "            }\n",
        "            \n",
        "            for frame in tracking_frames:\n",
        "                frame_data = {\n",
        "                    \"frame_number\": frame.frame_number,\n",
        "                    \"timestamp\": frame.timestamp,\n",
        "                    \"detections\": []\n",
        "                }\n",
        "                \n",
        "                for detection in frame.detections:\n",
        "                    detection_data = {\n",
        "                        \"object_id\": detection.object_id,\n",
        "                        \"class\": detection.class_name,\n",
        "                        \"confidence\": detection.confidence,\n",
        "                        \"bbox\": detection.bbox,\n",
        "                        \"center_normalized\": detection.center,\n",
        "                        \"camera_angle\": detection.camera_angle\n",
        "                    }\n",
        "                    frame_data[\"detections\"].append(detection_data)\n",
        "                \n",
        "                tracking_data[\"frames\"].append(frame_data)\n",
        "            \n",
        "            with open(output_path, 'w') as f:\n",
        "                json.dump(tracking_data, f, indent=2)\n",
        "            \n",
        "            logger.info(f\"Tracking data exported: {output_path}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error exporting tracking data: {e}\")\n",
        "    \n",
        "    def _generate_summary(self, tracking_frames: List[TrackingFrame], input_videos: List[str]) -> Dict:\n",
        "        \"\"\"Generate tracking summary statistics\"\"\"\n",
        "        try:\n",
        "            all_player_ids = set()\n",
        "            ball_detections = 0\n",
        "            total_detections = 0\n",
        "            \n",
        "            for frame in tracking_frames:\n",
        "                for detection in frame.detections:\n",
        "                    total_detections += 1\n",
        "                    if detection.class_name == 'person':\n",
        "                        all_player_ids.add(detection.object_id)\n",
        "                    elif detection.class_name == 'sports ball':\n",
        "                        ball_detections += 1\n",
        "            \n",
        "            duration = tracking_frames[-1].timestamp if tracking_frames else 0\n",
        "            \n",
        "            return {\n",
        "                \"input_videos\": [Path(v).name for v in input_videos],\n",
        "                \"duration_seconds\": duration,\n",
        "                \"total_frames\": len(tracking_frames),\n",
        "                \"unique_players\": len(all_player_ids),\n",
        "                \"ball_detections\": ball_detections,\n",
        "                \"total_detections\": total_detections,\n",
        "                \"avg_detections_per_frame\": total_detections / len(tracking_frames) if tracking_frames else 0,\n",
        "                \"ball_visibility_percent\": (ball_detections / len(tracking_frames) * 100) if tracking_frames else 0\n",
        "            }\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error generating summary: {e}\")\n",
        "            return {}\n",
        "    \n",
        "    def print_result_summary(self, result: TrackingResult):\n",
        "        \"\"\"Print tracking result summary\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"üèÄ BASKETBALL TRACKING PREPROCESSING COMPLETE\")\n",
        "        print(\"=\"*60)\n",
        "        \n",
        "        print(f\"\\nüìπ Input Videos: {', '.join([Path(v).name for v in result.input_videos])}\")\n",
        "        print(f\"‚è±Ô∏è Processing Time: {result.processing_time:.2f} seconds\")\n",
        "        print(f\"üé¨ Total Frames: {result.total_frames}\")\n",
        "        print(f\"üë• Players Tracked: {result.players_tracked}\")\n",
        "        print(f\"üèÄ Ball Detections: {result.ball_detections}\")\n",
        "        \n",
        "        print(f\"\\nüìä TRACKING INSIGHTS:\")\n",
        "        summary = result.summary\n",
        "        print(f\"  Duration: {summary.get('duration_seconds', 0):.1f} seconds\")\n",
        "        print(f\"  Avg Detections/Frame: {summary.get('avg_detections_per_frame', 0):.1f}\")\n",
        "        print(f\"  Ball Visibility: {summary.get('ball_visibility_percent', 0):.1f}%\")\n",
        "        \n",
        "        print(f\"\\nüìÅ OUTPUT FILES:\")\n",
        "        print(f\"  üé• Tracking Video: {Path(result.output_video).name}\")\n",
        "        print(f\"  üìÑ Tracking Data: {Path(result.tracking_data_file).name}\")\n",
        "        \n",
        "        print(f\"\\n‚úÖ Ready for analysis in basketball_poc notebook!\")\n",
        "        print(f\"üìç Use tracking video: {result.output_video}\")\n",
        "        print(f\"üìç Optional tracking data: {result.tracking_data_file}\")\n",
        "\n",
        "# Initialize main pipeline\n",
        "tracking_pipeline = BasketballTrackingPipeline(config)\n",
        "print(\"‚úÖ Basketball tracking pipeline initialized\")\n",
        "print(\"üéØ Ready to process multi-angle basketball videos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Usage Examples and Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find available videos in data folder\n",
        "print(\"üèÄ BASKETBALL TRACKING PREPROCESSOR\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Look for basketball videos\n",
        "available_videos = []\n",
        "if Path(\"data\").exists():\n",
        "    for file in Path(\"data\").iterdir():\n",
        "        if file.suffix.lower() in ['.mp4', '.avi', '.mov', '.mkv']:\n",
        "            available_videos.append(str(file))\n",
        "\n",
        "print(f\"\\nüìÅ Found {len(available_videos)} videos:\")\n",
        "for i, video in enumerate(available_videos[:10], 1):\n",
        "    size_mb = Path(video).stat().st_size / (1024*1024)\n",
        "    print(f\"  {i}. {Path(video).name} ({size_mb:.1f} MB)\")\n",
        "\n",
        "if len(available_videos) >= 2:\n",
        "    print(f\"\\nüéØ PROCESSING MULTI-ANGLE VIDEOS\")\n",
        "    print(\"Using first two videos as backboard angles...\")\n",
        "    \n",
        "    video1 = available_videos[0]\n",
        "    video2 = available_videos[1] if len(available_videos) > 1 else available_videos[0]\n",
        "    \n",
        "    print(f\"\\nüìπ Angle 1: {Path(video1).name}\")\n",
        "    print(f\"üìπ Angle 2: {Path(video2).name}\")\n",
        "    \n",
        "    try:\n",
        "        # Process the videos\n",
        "        result = tracking_pipeline.process_multi_angle_videos(\n",
        "            video1, video2, \n",
        "            output_name=\"backboard_angles\"\n",
        "        )\n",
        "        \n",
        "        # Print results\n",
        "        tracking_pipeline.print_result_summary(result)\n",
        "        \n",
        "        print(f\"\\nüéâ SUCCESS! Tracking preprocessing completed!\")\n",
        "        print(f\"\\nüí° NEXT STEPS:\")\n",
        "        print(f\"1. Use the tracking-enhanced video in your main analysis:\")\n",
        "        print(f\"   üìπ {result.output_video}\")\n",
        "        print(f\"2. The tracking data is also available for advanced analysis:\")\n",
        "        print(f\"   üìÑ {result.tracking_data_file}\")\n",
        "        print(f\"3. Run your basketball_poc notebook with the enhanced video!\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå Error in multi-angle processing: {e}\")\n",
        "        print(f\"\\nüîÑ Trying single video mode...\")\n",
        "        \n",
        "        try:\n",
        "            result = tracking_pipeline.process_single_video(\n",
        "                video1, \n",
        "                output_name=\"single_angle\"\n",
        "            )\n",
        "            tracking_pipeline.print_result_summary(result)\n",
        "            print(f\"\\n‚úÖ Single video processing completed!\")\n",
        "            \n",
        "        except Exception as e2:\n",
        "            print(f\"‚ùå Single video processing also failed: {e2}\")\n",
        "            print(f\"üí° Please check video files and try again\")\n",
        "\n",
        "elif len(available_videos) == 1:\n",
        "    print(f\"\\nüéØ PROCESSING SINGLE VIDEO\")\n",
        "    print(\"Only one video found, processing in single-angle mode...\")\n",
        "    \n",
        "    try:\n",
        "        result = tracking_pipeline.process_single_video(\n",
        "            available_videos[0],\n",
        "            output_name=\"single_basketball\"\n",
        "        )\n",
        "        tracking_pipeline.print_result_summary(result)\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Single video processing failed: {e}\")\n",
        "\n",
        "else:\n",
        "    print(f\"\\n‚ùå No basketball videos found in data/ folder\")\n",
        "    print(f\"\\nüí° TO GET STARTED:\")\n",
        "    print(f\"1. Add your basketball videos to the data/ folder\")\n",
        "    print(f\"2. For best results, use 2 videos from different backboard angles\")\n",
        "    print(f\"3. Videos should be synchronized (same game time)\")\n",
        "    print(f\"4. Supported formats: .mp4, .avi, .mov, .mkv\")\n",
        "    print(f\"5. Re-run this cell to process your videos\")\n",
        "\n",
        "print(f\"\\n\" + \"=\" * 50)\n",
        "print(f\"üìã TRACKING PREPROCESSOR READY\")\n",
        "print(f\"‚Ä¢ Multi-angle video stitching\")\n",
        "print(f\"‚Ä¢ Player and ball tracking with TrackStudio\")\n",
        "print(f\"‚Ä¢ Visual overlays with bounding boxes and trails\")\n",
        "print(f\"‚Ä¢ JSON export for downstream analysis\")\n",
        "print(f\"‚Ä¢ Integration ready for basketball_poc notebook\")\n",
        "print(f\"=\" * 50)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",\n      "language": "python",\n      "name": "python3"\n    },\n    "language_info": {\n      "codemirror_mode": {\n        "name": "ipython",\n        "version": 3\n      },\n      "file_extension": ".py",\n      "mimetype": "text/x-python",\n      "name": "python",\n      "nbconvert_exporter": "python",\n      "pygments_lexer": "ipython3",\n      "version": "3.8.5"\n    }\n  },\n  "nbformat": 4,\n  "nbformat_minor": 4\n}